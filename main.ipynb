{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6e8f11-acc0-4a7f-b360-d04cb08d5da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from modelscope import snapshot_download\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9128de6-50b0-4d11-b0f4-b9a200f3e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels=['涉政','色情','暴力','正常']\n",
    "json_data = []\n",
    "with open('./dataset/data.jsonl','r',encoding='utf-8') as f:\n",
    "    for data in f.readlines():\n",
    "        data_dict = json.loads(data)\n",
    "        json_data.append(data_dict)\n",
    "with open('./dataset.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for data in json_data:\n",
    "        data['input'] = data['text']\n",
    "        data['output'] = labels[data['label']]\n",
    "        del data['text']       # 正确删除 key\n",
    "        del data['label']\n",
    "        f.write(json.dumps(data, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8eab0d7-36b4-45f1-89dc-c1d0f4b1fd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3763"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_datasets = []\n",
    "with open('./dataset.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for data in f.readlines():\n",
    "        json_datasets.append(json.loads(data))\n",
    "len(json_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b31dfe9-11c6-449d-897e-fe369bf60c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /boot/qwen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "#模型下载\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('Qwen/Qwen3-4B',local_dir='./qwen')\n",
    "model = AutoModelForCausalLM.from_pretrained('./qwen')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./qwen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3316bce-fe98-4015-a73b-23577e18edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(dataset,max_length):\n",
    "    new_dataset = []\n",
    "    flags=['涉政','色情','暴力','正常']\n",
    "    content = \"\"\"\n",
    "        请根据下列用户输入的文本:{text}，从候选标签:{labels}中选择最合适的一个标签作为输出。\n",
    "        请严格只输出最可能的一个标签，不要输出解释或任何额外内容。\n",
    "        \"\"\"\n",
    "    for data in dataset:\n",
    "        q = data['input']\n",
    "        a = data['output']\n",
    "        \n",
    "        prompt = [{\"role\":\"user\",\"content\":content.format(text=q,labels=flags)}]\n",
    "        # 使用 tokenizer 处理文本\n",
    "        q = tokenizer.apply_chat_template(prompt, tokenize=False,add_generation_prompt=True)\n",
    "       \n",
    "        # print(len(q))\n",
    "        q_input_ids = tokenizer.encode(q,add_special_tokens=False)\n",
    "        a_input_ids = tokenizer.encode(a,add_special_tokens=False)\n",
    "        input_ids = q_input_ids+a_input_ids\n",
    "        # print(len(input_ids))\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        labels= len(q_input_ids)*[-100] + a_input_ids\n",
    "       \n",
    "        if len(input_ids)<max_length:\n",
    "            padding_length = max_length - len(input_ids) \n",
    "            input_ids = [tokenizer.pad_token_id] * padding_length + input_ids\n",
    "            labels = [-100]*padding_length + labels\n",
    "            attention_mask = [0]*padding_length + attention_mask\n",
    "        else:\n",
    "            input_ids = input_ids[:max_length]\n",
    "            labels = labels[:max_length]\n",
    "            attention_mask = attention_mask[:max_length]\n",
    "        new_dataset.append( {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        })\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7990f6-ee5b-45b7-b634-62866a6f6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = token(dataset=json_datasets,max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b830b218-d4a0-4aea-8c14-f3f3c735082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels=['涉政','色情','暴力','正常']\n",
    "from torch.utils.data import Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, datasets):\n",
    "        super().__init__()\n",
    "        self.datasets = datasets  # 保存数据\n",
    "    def __len__(self):\n",
    "        return len(self.datasets)\n",
    "    def __getitem__(self, idx):\n",
    "        data =  self.datasets[idx]\n",
    "        return {\n",
    "        \"input_ids\": torch.tensor(data['input_ids'], dtype=torch.long),\n",
    "        \"attention_mask\": torch.tensor(data['attention_mask'], dtype=torch.long),\n",
    "        \"labels\": torch.tensor(data['labels'], dtype=torch.long),\n",
    "        }\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f138e2e-9763-4c72-9a3e-74cdb099e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  =MyDataset(datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ab0ed8-11eb-4a46-8bdd-cb9b68ba8fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,949,120 || all params: 4,025,417,216 || trainable%: 0.0733\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "# LoRA 配置示例\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\", \"q_proj\",\"v_proj\"],  # GPT2 相关模块示例\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ed05b1c-7751-4208-a917-3650012b91de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1882/1882 [07:33<00:00,  4.15it/s, loss=0.000339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 average loss: 0.17393784378823082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./trained/tokenizer_config.json',\n",
       " './trained/special_tokens_map.json',\n",
       " './trained/chat_template.jinja',\n",
       " './trained/vocab.json',\n",
       " './trained/merges.txt',\n",
       " './trained/added_tokens.json',\n",
       " './trained/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(1):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    total_loss = 0\n",
    "    for batch in loop:\n",
    "        # print(batch)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        # print(labels)\n",
    "        # break\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        # 检查 loss 是否为 NaN\n",
    "        if torch.isnan(loss):\n",
    "            print(\"⚠️ NaN loss detected. Skipping batch.\")\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    print(f\"Epoch {epoch} average loss: {total_loss / len(train_loader)}\")\n",
    "output_dir = './trained'\n",
    "# 保存微调好的模型\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec3961d-4302-48dc-873c-f676861c9782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成结果： user\n",
      "你是一位专业的文本分类专家。请根据下列用户输入的文本，从候选标签中选择最合适的一个标签作为输出。\n",
      "        文本：她的阴蒂又大又敏感，一碰就高潮\n",
      "        候选标签：['涉政', '色情', '暴力', '正常']\n",
      "        请严格只输出最可能的一个标签，不要输出解释或任何额外内容。\n",
      "\n",
      "assistant\n",
      "色情\n",
      "</think>\n",
      "\n",
      "色情\n"
     ]
    }
   ],
   "source": [
    "# 加载微调好的模型进行推理\n",
    "output_dir = './trained'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 加载模型和 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(output_dir)\n",
    "model.to(device)  # 加载到 GPU 或 CPU\n",
    "model.eval()\n",
    "# 输入文本\n",
    "text = \"她的阴蒂又大又敏感，一碰就高潮\"\n",
    "flags=['涉政','色情','暴力','正常']\n",
    "input_text = \"\"\"你是一位专业的文本分类专家。请根据下列用户输入的文本，从候选标签中选择最合适的一个标签作为输出。\n",
    "        文本：{text}\n",
    "        候选标签：{labels}\n",
    "        请严格只输出最可能的一个标签，不要输出解释或任何额外内容。\n",
    "\"\"\"\n",
    "prompt = input_text.format(text=text,labels=flags)\n",
    "content = [{\"role\":\"user\",\"content\":prompt}]\n",
    "q =tokenizer.apply_chat_template(content,tokenize=False,add_generation_prompt=True)\n",
    "# 编码输入\n",
    "inputs = tokenizer(q, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# 文本生成\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,            # 控制生成长度\n",
    "        do_sample=False,               # 使用采样以增加多样性（也可设为 False 走贪心）\n",
    "        top_k=50,                     # top-k 采样\n",
    "        top_p=0.95,                   # nucleus sampling\n",
    "        temperature=0.8,              # 控制生成多样性\n",
    "        pad_token_id=tokenizer.eos_token_id  # 避免 padding 报错\n",
    "    )\n",
    "\n",
    "# 解码输出\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"生成结果：\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c93d17-9c00-45f2-800a-e19d3dfc384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成结果： user\n",
      "你是一位专业的文本分类专家。请根据下列用户输入的文本，从候选标签中选择最合适的一个标签作为输出。\n",
      "        文本：她的阴蒂又大又敏感，一碰就高潮\n",
      "        候选标签：['涉政', '色情', '暴力', '正常']\n",
      "        请严格只输出最可能的一个标签，不要输出解释或任何额外内容。\n",
      "\n",
      "assistant\n",
      "<think>\n",
      "好的，我现在需要处理用户的这个文本分类请求。首先，用户给出的文本是：“她的阴蒂又大又敏感，一碰就高潮”。候选标签有四个：涉政、色情、暴力、正常。我需要\n"
     ]
    }
   ],
   "source": [
    "output_dir = './qwen'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 加载模型和 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(output_dir)\n",
    "model.to(device)  # 加载到 GPU 或 CPU\n",
    "model.eval()\n",
    "# 输入文本\n",
    "text = \"她的阴蒂又大又敏感，一碰就高潮\"\n",
    "flags=['涉政','色情','暴力','正常']\n",
    "input_text = \"\"\"你是一位专业的文本分类专家。请根据下列用户输入的文本，从候选标签中选择最合适的一个标签作为输出。\n",
    "        文本：{text}\n",
    "        候选标签：{labels}\n",
    "        请严格只输出最可能的一个标签，不要输出解释或任何额外内容。\n",
    "\"\"\"\n",
    "prompt = input_text.format(text=text,labels=flags)\n",
    "content = [{\"role\":\"user\",\"content\":prompt}]\n",
    "q =tokenizer.apply_chat_template(content,tokenize=False,add_generation_prompt=True)\n",
    "# 编码输入\n",
    "inputs = tokenizer(q, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# 文本生成\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,            # 控制生成长度\n",
    "        do_sample=False,               # 使用采样以增加多样性（也可设为 False 走贪心）\n",
    "        top_k=50,                     # top-k 采样\n",
    "        top_p=0.95,                   # nucleus sampling\n",
    "        temperature=0.8,              # 控制生成多样性\n",
    "        pad_token_id=tokenizer.eos_token_id  # 避免 padding 报错\n",
    "    )\n",
    "\n",
    "# 解码输出\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"生成结果：\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37eebf-1986-4711-84ed-056349c38c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7740f17-7fd1-4b4a-86d9-04cffe4ffafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e209e-6abb-4bcf-b2a2-3c4ec8d07d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a9607-9486-47ae-b2ff-78962c593c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640839a-8615-426c-a497-b81770310d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd94fd7-6677-4a08-8e34-0fb92da4bd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f2e49-ef33-4be5-a22f-33e78eb55255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ef1c1-4ee3-4803-9357-32f1ce2f3afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe05d77-0d9e-4e82-9ae7-055778943bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f1efd-e3ee-4cac-aa79-7fdf3c78070d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
