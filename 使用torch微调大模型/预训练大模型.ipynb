{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae81d28-f36a-46e8-81f6-a32e10eb5b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import modelscope\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ecbf8d8-9738-4b53-a27f-a736a2f62a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./muice-dataset-train.catgirl (2).json','r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1178bb-774d-404c-97d3-bbbc44d8a05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for d in data:\n",
    "    max_len = max(len(d['instruction']),max_len)\n",
    "    max_len = max(len(d['output']),max_len)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee76ace-13c9-445d-a47d-d670f091a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e56dce75-1f23-4c5f-a870-609d6a2cdd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"./DeepSeek\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./DeepSeek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35cfa8f8-a1ba-43cf-bc8a-bc2a57aab1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def token(example,max_length=180):\n",
    "#     instruction = example['instruction']\n",
    "#     output = example['output']\n",
    "#     prompt = [{\"role\":\"user\",\"content\":instruction}]\n",
    "#     prompt_token = tokenizer.apply_chat_template(prompt,tokenize=False)\n",
    "#     q = tokenizer.encode(prompt_token)\n",
    "#     a = tokenizer.encode(output)\n",
    "#     input_ids = q+a\n",
    "#     labels = a\n",
    "#     attention_mask = [-100]*len(q) + [1]*len(a)\n",
    "#     if len(input_ids)<=max_length:\n",
    "#         padding_length = max_length-len(input_ids)\n",
    "#         input_ids = [-100]*padding_length+ input_ids\n",
    "#         labels = [-100]*(padding_length+len(q)) +labels\n",
    "#         attention_mask = [0]*padding_length+attention_mask\n",
    "#     else:\n",
    "#         input_ids = input_ids[:max_length]\n",
    "#         labels = labels[:max_length]\n",
    "#         attention_mask = attention_mask[:max_length]\n",
    "#     return {\n",
    "#         \"input_ids\":input_ids,\n",
    "#         \"labels\":labels,\n",
    "#         \"attention_mask\":attention_mask\n",
    "#     }\n",
    "# def token(example, max_length=180):\n",
    "#     instruction = example['instruction']\n",
    "#     output = example['output']\n",
    "#     prompt = [{\"role\": \"user\", \"content\": example[\"instruction\"]}]\n",
    "#     prompt_token = tokenizer.apply_chat_template(prompt, tokenize=False)\n",
    "#     tokenized = tokenizer(\n",
    "#         prompt_token,\n",
    "#         text_target=example[\"output\"],\n",
    "#         max_length=max_length,\n",
    "#         padding=\"max_length\",\n",
    "#         truncation=True,\n",
    "#         return_tensors=\"pt\",\n",
    "#     )\n",
    "#     input_ids = tokenized[\"input_ids\"][0]\n",
    "#     labels = tokenized[\"labels\"][0]\n",
    "#     attention_mask = tokenized[\"attention_mask\"][0]\n",
    "  \n",
    "    \n",
    "#     if len(input_ids) < max_length:\n",
    "#         pad_len = max_length - len(input_ids)\n",
    "#         input_ids = [tokenizer.pad_token_id] * pad_len + input_ids\n",
    "#         attention_mask = [0] * pad_len + attention_mask\n",
    "#         labels = [-100] * pad_len + labels\n",
    "#     else:\n",
    "#         input_ids = input_ids[:max_length]\n",
    "#         attention_mask = attention_mask[:max_length]\n",
    "#         labels = labels[:max_length]\n",
    "  # prompt = [{\"role\": \"user\", \"content\": instruction}]\n",
    "    # prompt_token = tokenizer.apply_chat_template(prompt, tokenize=False)\n",
    "    \n",
    "    # q = tokenizer.encode(prompt_token, add_special_tokens=False)\n",
    "    # a = tokenizer.encode(output, add_special_tokens=False)\n",
    "    \n",
    "    # input_ids = q + a\n",
    "    # attention_mask = [-100] * len(q) + [1] * len(a)\n",
    "    # labels = [-100] * len(q) + a\n",
    "def token(example, max_length=180):\n",
    "    instruction = example['instruction']\n",
    "    output = example['output']\n",
    "    prompt = [{\"role\": \"user\", \"content\": example[\"instruction\"]}]\n",
    "    q = tokenizer.apply_chat_template(prompt, tokenize=False,add_generation_prompt=True)\n",
    "    \n",
    "    q_input_ids = tokenizer.encode(q)\n",
    "    a_input_ids = tokenizer.encode(output)\n",
    "    input_ids = q_input_ids+a_input_ids\n",
    "    attention_mask = [1]*len(input_ids)\n",
    "    labels = [-100]*len(q_input_ids)+a_input_ids\n",
    "    if len(input_ids) < max_length:\n",
    "        pad_len = max_length - len(input_ids)\n",
    "        input_ids = [tokenizer.pad_token_id] * pad_len + input_ids\n",
    "        attention_mask = [0] * pad_len + attention_mask\n",
    "        labels = [-100] * pad_len + labels\n",
    "    else:\n",
    "        input_ids = input_ids[:max_length]\n",
    "        attention_mask = attention_mask[:max_length]\n",
    "        labels = labels[:max_length]\n",
    "    \n",
    "    # Sanity check\n",
    "    assert len(input_ids) == max_length\n",
    "    assert len(labels) == max_length\n",
    "    assert len(attention_mask) == max_length\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels,\n",
    "        \"attention_mask\": attention_mask\n",
    "    }\n",
    "\n",
    "data_ids = []\n",
    "for d in data:\n",
    "    id_dict = token(d)\n",
    "    data_ids.append(id_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dcad623-77e7-4592-8385-eacb9977c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class MyData(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(data[\"input_ids\"], dtype=torch.long),\n",
    "            \"labels\": torch.tensor(data[\"labels\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(data[\"attention_mask\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fcd266-0649-4e6f-8cc7-1c41a5700664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ids[:5]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d57da50-8dc5-4093-ad0f-f500c81be078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "my_data = MyData(data_ids)\n",
    "train_dataloader = DataLoader(my_data, shuffle=True, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8a2c4e-38bc-4bcc-8fc9-98d5a941d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151643"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b26319-8b28-40fd-b196-e342159d10ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/483 [00:45<6:03:02, 45.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.780388832092285\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for i,batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42d06a-6667-4fad-9d07-eb0732d81b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d91cb01-5548-4a98-a70c-7c373a885d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
