{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae81d28-f36a-46e8-81f6-a32e10eb5b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import modelscope\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ecbf8d8-9738-4b53-a27f-a736a2f62a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./muice-dataset-train.catgirl (2).json','r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1178bb-774d-404c-97d3-bbbc44d8a05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for d in data:\n",
    "    max_len = max(len(d['instruction']),max_len)\n",
    "    max_len = max(len(d['output']),max_len)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee76ace-13c9-445d-a47d-d670f091a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e56dce75-1f23-4c5f-a870-609d6a2cdd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"./DeepSeek\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./DeepSeek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35cfa8f8-a1ba-43cf-bc8a-bc2a57aab1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def token(example,max_length=180):\n",
    "#     instruction = example['instruction']\n",
    "#     output = example['output']\n",
    "#     prompt = [{\"role\":\"user\",\"content\":instruction}]\n",
    "#     prompt_token = tokenizer.apply_chat_template(prompt,tokenize=False)\n",
    "#     q = tokenizer.encode(prompt_token)\n",
    "#     a = tokenizer.encode(output)\n",
    "#     input_ids = q+a\n",
    "#     labels = a\n",
    "#     attention_mask = [-100]*len(q) + [1]*len(a)\n",
    "#     if len(input_ids)<=max_length:\n",
    "#         padding_length = max_length-len(input_ids)\n",
    "#         input_ids = [-100]*padding_length+ input_ids\n",
    "#         labels = [-100]*(padding_length+len(q)) +labels\n",
    "#         attention_mask = [0]*padding_length+attention_mask\n",
    "#     else:\n",
    "#         input_ids = input_ids[:max_length]\n",
    "#         labels = labels[:max_length]\n",
    "#         attention_mask = attention_mask[:max_length]\n",
    "#     return {\n",
    "#         \"input_ids\":input_ids,\n",
    "#         \"labels\":labels,\n",
    "#         \"attention_mask\":attention_mask\n",
    "#     }\n",
    "\n",
    "def token(example, max_length=180):\n",
    "    instruction = example['instruction']\n",
    "    output = example['output']\n",
    "    prompt = [{\"role\": \"user\", \"content\": example[\"instruction\"]}]\n",
    "    prompt_token = tokenizer.apply_chat_template(prompt, tokenize=False)\n",
    "    tokenized = tokenizer(\n",
    "        prompt_token,\n",
    "        text_target=example[\"output\"],\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = tokenized[\"input_ids\"][0]\n",
    "    labels = tokenized[\"labels\"][0]\n",
    "    attention_mask = tokenized[\"attention_mask\"][0]\n",
    "    # prompt = [{\"role\": \"user\", \"content\": instruction}]\n",
    "    # prompt_token = tokenizer.apply_chat_template(prompt, tokenize=False)\n",
    "    \n",
    "    # q = tokenizer.encode(prompt_token, add_special_tokens=False)\n",
    "    # a = tokenizer.encode(output, add_special_tokens=False)\n",
    "    \n",
    "    # input_ids = q + a\n",
    "    # attention_mask = [-100] * len(q) + [1] * len(a)\n",
    "    # labels = [-100] * len(q) + a\n",
    "    \n",
    "    if len(input_ids) < max_length:\n",
    "        pad_len = max_length - len(input_ids)\n",
    "        input_ids = [-100] * pad_len + input_ids\n",
    "        attention_mask = [0] * pad_len + attention_mask\n",
    "        labels = [-100] * pad_len + labels\n",
    "    else:\n",
    "        input_ids = input_ids[:max_length]\n",
    "        attention_mask = attention_mask[:max_length]\n",
    "        labels = labels[:max_length]\n",
    "    \n",
    "    # Sanity check\n",
    "    assert len(input_ids) == max_length\n",
    "    assert len(labels) == max_length\n",
    "    assert len(attention_mask) == max_length\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels,\n",
    "        \"attention_mask\": attention_mask\n",
    "    }\n",
    "\n",
    "data_ids = []\n",
    "for d in data:\n",
    "    id_dict = token(d)\n",
    "    data_ids.append(id_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981b779e-923d-41bb-ac4a-34dc55320391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ids[0:5]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ceb6ec7-1346-4214-905e-44359044cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dcad623-77e7-4592-8385-eacb9977c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(data[\"input_ids\"], dtype=torch.long),\n",
    "            \"labels\": torch.tensor(data[\"labels\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(data[\"attention_mask\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89fcd266-0649-4e6f-8cc7-1c41a5700664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ids[:5]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d57da50-8dc5-4093-ad0f-f500c81be078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "my_data = MyData(data_ids)\n",
    "train_dataloader = DataLoader(my_data, shuffle=True, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b8a2c4e-38bc-4bcc-8fc9-98d5a941d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d93466b-15ea-434e-be1c-731fbbc95ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f503a6a3-de0d-42c1-8881-7fbf7650e4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_328/617158398.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"input_ids\": torch.tensor(data[\"input_ids\"], dtype=torch.long),\n",
      "/tmp/ipykernel_328/617158398.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"labels\": torch.tensor(data[\"labels\"], dtype=torch.long),\n",
      "/tmp/ipykernel_328/617158398.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"attention_mask\": torch.tensor(data[\"attention_mask\"], dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=tensor(15.1646, grad_fn=<NllLossBackward0>), logits=tensor([[[ 3.6944,  9.2059, 12.8443,  ...,  1.7534,  1.7535,  1.7541],\n",
       "         [ 3.6944,  9.2059, 12.8443,  ...,  1.7534,  1.7535,  1.7541],\n",
       "         [ 3.6944,  9.2059, 12.8443,  ...,  1.7534,  1.7535,  1.7541],\n",
       "         ...,\n",
       "         [ 3.7767,  3.0902,  4.3630,  ..., -5.2807, -5.2813, -5.2814],\n",
       "         [10.6131,  2.9426,  1.4239,  ..., -2.9594, -2.9604, -2.9578],\n",
       "         [ 6.0673,  1.1889, -0.4581,  ..., -2.8378, -2.8394, -2.8355]],\n",
       "\n",
       "        [[ 3.7610,  9.2776, 12.6995,  ...,  1.8393,  1.8394,  1.8401],\n",
       "         [ 3.7610,  9.2776, 12.6995,  ...,  1.8393,  1.8394,  1.8401],\n",
       "         [ 3.7610,  9.2776, 12.6995,  ...,  1.8393,  1.8394,  1.8401],\n",
       "         ...,\n",
       "         [-2.4719,  1.5390,  1.8533,  ..., -3.6610, -3.6625, -3.6593],\n",
       "         [ 0.2889, -0.6669,  0.7301,  ..., -2.6831, -2.6833, -2.6812],\n",
       "         [ 3.6570,  3.6163,  2.2349,  ..., -4.5985, -4.5986, -4.5955]],\n",
       "\n",
       "        [[ 4.1253,  9.6131, 12.6197,  ...,  1.9698,  1.9699,  1.9707],\n",
       "         [ 4.1253,  9.6131, 12.6197,  ...,  1.9698,  1.9699,  1.9707],\n",
       "         [ 4.1253,  9.6131, 12.6197,  ...,  1.9698,  1.9699,  1.9707],\n",
       "         ...,\n",
       "         [ 2.2750,  4.3376,  2.8710,  ..., -1.7113, -1.7125, -1.7101],\n",
       "         [ 5.8044,  6.8784,  6.6539,  ..., -1.4078, -1.4080, -1.4061],\n",
       "         [ 1.4457,  7.2142,  5.7334,  ..., -4.1404, -4.1406, -4.1369]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 4.1589,  9.3839, 12.5253,  ...,  1.9164,  1.9165,  1.9173],\n",
       "         [ 4.1589,  9.3839, 12.5253,  ...,  1.9164,  1.9165,  1.9173],\n",
       "         [ 4.1589,  9.3839, 12.5253,  ...,  1.9164,  1.9165,  1.9173],\n",
       "         ...,\n",
       "         [ 5.7662,  1.8039,  0.5819,  ..., -4.7878, -4.7893, -4.7876],\n",
       "         [ 5.3749,  6.1002,  2.9099,  ..., -4.1881, -4.1888, -4.1861],\n",
       "         [ 8.0238,  7.6902,  4.8936,  ..., -3.4978, -3.4985, -3.4970]],\n",
       "\n",
       "        [[ 4.2253,  9.4598, 12.6588,  ...,  2.0656,  2.0657,  2.0665],\n",
       "         [ 4.2253,  9.4598, 12.6588,  ...,  2.0656,  2.0657,  2.0665],\n",
       "         [ 4.2253,  9.4598, 12.6588,  ...,  2.0656,  2.0657,  2.0665],\n",
       "         ...,\n",
       "         [ 1.1854,  0.5728, -0.1559,  ..., -3.7053, -3.7062, -3.7026],\n",
       "         [ 3.2152,  4.8162,  0.5586,  ..., -3.9066, -3.9071, -3.9046],\n",
       "         [ 5.9117,  6.9419,  4.3923,  ..., -3.5577, -3.5581, -3.5559]],\n",
       "\n",
       "        [[ 3.9652,  9.2485, 12.7016,  ...,  1.9175,  1.9175,  1.9183],\n",
       "         [ 3.9652,  9.2485, 12.7016,  ...,  1.9175,  1.9175,  1.9183],\n",
       "         [ 3.9652,  9.2485, 12.7016,  ...,  1.9175,  1.9175,  1.9183],\n",
       "         ...,\n",
       "         [ 1.9637,  3.9654,  2.4935,  ..., -2.3658, -2.3658, -2.3630],\n",
       "         [-0.1395,  5.9115,  3.9101,  ..., -3.5085, -3.5092, -3.5059],\n",
       "         [ 8.1634,  4.5524,  1.3673,  ..., -3.1460, -3.1470, -3.1431]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=<transformers.cache_utils.DynamicCache object at 0x7fdba26bd750>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "model(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42d06a-6667-4fad-9d07-eb0732d81b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d91cb01-5548-4a98-a70c-7c373a885d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
